{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e51930a",
   "metadata": {},
   "source": [
    "# Planes VLM Eval — no cache, no file writes\n",
    "\n",
    "Этот ноутбук — упрощённая версия пайплайна:\n",
    "\n",
    "- **Без кэширования** и **без сохранения файлов** (CSV, PNG и т.п.).\n",
    "- Вывод **поэтапно** прямо в ячейках Jupyter (таблица результатов обновляется в процессе, метрики считаются онлайн).\n",
    "- Используется Hugging Face Inference Router в формате OpenAI API.\n",
    "\n",
    "Перед запуском:\n",
    "1. Установите зависимости (см. ячейку ниже).\n",
    "2. Убедитесь, что у вас выставлена переменная окружения `HF_TOKEN` (например, через `.env`).\n",
    "3. Укажите корректные пути `DATA_DIR` и, при наличии, `LABELS_CSV`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c16f196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /home/vasaby/Documents/Georgiy/Институт/МАГА/ИСИТ/.venv/lib/python3.12/site-packages (1.2.1)\n",
      "Requirement already satisfied: openai in /home/vasaby/Documents/Georgiy/Институт/МАГА/ИСИТ/.venv/lib/python3.12/site-packages (2.6.1)\n",
      "Requirement already satisfied: pillow in /home/vasaby/Documents/Georgiy/Институт/МАГА/ИСИТ/.venv/lib/python3.12/site-packages (12.0.0)\n",
      "Requirement already satisfied: tqdm in /home/vasaby/Documents/Georgiy/Институт/МАГА/ИСИТ/.venv/lib/python3.12/site-packages (4.67.1)\n",
      "Requirement already satisfied: pandas in /home/vasaby/Documents/Georgiy/Институт/МАГА/ИСИТ/.venv/lib/python3.12/site-packages (2.3.3)\n",
      "Requirement already satisfied: scikit-learn in /home/vasaby/Documents/Georgiy/Институт/МАГА/ИСИТ/.venv/lib/python3.12/site-packages (1.7.2)\n",
      "Requirement already satisfied: matplotlib in /home/vasaby/Documents/Georgiy/Институт/МАГА/ИСИТ/.venv/lib/python3.12/site-packages (3.10.7)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/vasaby/Documents/Georgiy/Институт/МАГА/ИСИТ/.venv/lib/python3.12/site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/vasaby/Documents/Georgiy/Институт/МАГА/ИСИТ/.venv/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/vasaby/Documents/Georgiy/Институт/МАГА/ИСИТ/.venv/lib/python3.12/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /home/vasaby/Documents/Georgiy/Институт/МАГА/ИСИТ/.venv/lib/python3.12/site-packages (from openai) (0.11.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/vasaby/Documents/Georgiy/Институт/МАГА/ИСИТ/.venv/lib/python3.12/site-packages (from openai) (2.12.3)\n",
      "Requirement already satisfied: sniffio in /home/vasaby/Documents/Georgiy/Институт/МАГА/ИСИТ/.venv/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /home/vasaby/Documents/Georgiy/Институт/МАГА/ИСИТ/.venv/lib/python3.12/site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in /home/vasaby/Documents/Georgiy/Институт/МАГА/ИСИТ/.venv/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
      "Requirement already satisfied: certifi in /home/vasaby/Documents/Georgiy/Институт/МАГА/ИСИТ/.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /home/vasaby/Documents/Georgiy/Институт/МАГА/ИСИТ/.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/vasaby/Documents/Georgiy/Институт/МАГА/ИСИТ/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/vasaby/Documents/Georgiy/Институт/МАГА/ИСИТ/.venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /home/vasaby/Documents/Georgiy/Институт/МАГА/ИСИТ/.venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /home/vasaby/Documents/Georgiy/Институт/МАГА/ИСИТ/.venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/vasaby/Documents/Georgiy/Институт/МАГА/ИСИТ/.venv/lib/python3.12/site-packages (from pandas) (2.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/vasaby/Documents/Georgiy/Институт/МАГА/ИСИТ/.venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/vasaby/Documents/Georgiy/Институт/МАГА/ИСИТ/.venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/vasaby/Documents/Georgiy/Институт/МАГА/ИСИТ/.venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /home/vasaby/Documents/Georgiy/Институт/МАГА/ИСИТ/.venv/lib/python3.12/site-packages (from scikit-learn) (1.16.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/vasaby/Documents/Georgiy/Институт/МАГА/ИСИТ/.venv/lib/python3.12/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/vasaby/Documents/Georgiy/Институт/МАГА/ИСИТ/.venv/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/vasaby/Documents/Georgiy/Институт/МАГА/ИСИТ/.venv/lib/python3.12/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/vasaby/Documents/Georgiy/Институт/МАГА/ИСИТ/.venv/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/vasaby/Documents/Georgiy/Институт/МАГА/ИСИТ/.venv/lib/python3.12/site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/vasaby/Documents/Georgiy/Институт/МАГА/ИСИТ/.venv/lib/python3.12/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/vasaby/Documents/Georgiy/Институт/МАГА/ИСИТ/.venv/lib/python3.12/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /home/vasaby/Documents/Georgiy/Институт/МАГА/ИСИТ/.venv/lib/python3.12/site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: six>=1.5 in /home/vasaby/Documents/Georgiy/Институт/МАГА/ИСИТ/.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U python-dotenv openai pillow tqdm pandas scikit-learn matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e081cd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import os, json, base64, time, re, random\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "from pathlib import Path\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (4,4)\n",
    "\n",
    "# ---- Global label space ----\n",
    "LABELS = (\"civilian\", \"military\")\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class VLMConfig:\n",
    "    name: str\n",
    "    provider: Optional[str] = None\n",
    "    temperature: float = 0.0\n",
    "    max_tokens: int = 200\n",
    "\n",
    "def normalize_label(s: str) -> str:\n",
    "    s = (s or \"\").strip().lower()\n",
    "    if s in LABELS:\n",
    "        return s\n",
    "    if \"civ\" in s or \"пасс\" in s or \"pass\" in s:\n",
    "        return \"civilian\"\n",
    "    if \"mil\" in s or \"арм\" in s or \"воен\" in s or \"army\" in s:\n",
    "        return \"military\"\n",
    "    return \"\"\n",
    "\n",
    "def collect_images(data_dir: Path) -> List[Path]:\n",
    "    exts = {\".jpg\", \".jpeg\", \".png\", \".webp\"}\n",
    "    return sorted([p for p in data_dir.iterdir() if p.is_file() and p.suffix.lower() in exts])\n",
    "\n",
    "def read_labels_csv(csv_path: Path) -> Dict[Path, str]:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    base = csv_path.parent\n",
    "    out: Dict[Path, str] = {}\n",
    "    for _, row in df.iterrows():\n",
    "        fn = base / str(row[\"filename\"])  # ожидание колонок: filename,label\n",
    "        out[fn.resolve()] = str(row[\"label\"]) \n",
    "    return out\n",
    "\n",
    "def infer_label_from_name(p: Path) -> str:\n",
    "    s = p.stem.lower()\n",
    "    if re.search(r\"mil(it|itary)?\", s) or \"воен\" in s or \"army\" in s:\n",
    "        return \"military\"\n",
    "    if re.search(r\"civ(il|ilian)?\", s) or \"pass\" in s or \"пасс\" in s:\n",
    "        return \"civilian\"\n",
    "    return \"\"\n",
    "\n",
    "def load_ground_truth(data_dir: Path, labels_csv: Optional[Path]) -> Dict[Path, str]:\n",
    "    imgs = collect_images(data_dir)\n",
    "    labels = read_labels_csv(labels_csv) if labels_csv and labels_csv.exists() else {}\n",
    "    gt: Dict[Path, str] = {}\n",
    "    for p in imgs:\n",
    "        lab = normalize_label(labels.get(p.resolve(), \"\") or infer_label_from_name(p))\n",
    "        if lab in LABELS:\n",
    "            gt[p] = lab\n",
    "    if not gt:\n",
    "        raise RuntimeError(\"Не найдено размеченных изображений (labels.csv или метка в имени файла).\")\n",
    "    return gt\n",
    "\n",
    "def encode_image_to_data_url(path: Path) -> str:\n",
    "    ext = path.suffix.lower().lstrip(\".\") or \"jpeg\"\n",
    "    if ext not in {\"jpg\", \"jpeg\", \"png\", \"webp\"}:\n",
    "        ext = \"jpeg\"\n",
    "    b64 = base64.b64encode(path.read_bytes()).decode(\"utf-8\")\n",
    "    return f\"data:image/{ext};base64,{b64}\"\n",
    "\n",
    "class HfVlmClassifier:\n",
    "    def __init__(self, api_key: str, cfg: VLMConfig):\n",
    "        self.client = OpenAI(base_url=\"https://router.huggingface.co/v1\", api_key=api_key)\n",
    "        self.model = f\"{cfg.name}:{cfg.provider}\" if cfg.provider else cfg.name\n",
    "        self.temperature = cfg.temperature\n",
    "        self.max_tokens = cfg.max_tokens\n",
    "\n",
    "    def classify(self, image_path: Path, retries: int = 3, backoff: float = 0.8) -> Dict:\n",
    "        img = encode_image_to_data_url(image_path)\n",
    "        prompt = (\n",
    "            \"Classify the airplane in this photo strictly as 'civilian' or 'military'. \"\n",
    "            \"Return JSON with fields: label, confidence (0..1), rationale.\"\n",
    "        )\n",
    "        last_err: Optional[Exception] = None\n",
    "        for attempt in range(retries + 1):\n",
    "            try:\n",
    "                r = self.client.chat.completions.create(\n",
    "                    model=self.model,\n",
    "                    messages=[{\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [\n",
    "                            {\"type\": \"text\", \"text\": prompt},\n",
    "                            {\"type\": \"image_url\", \"image_url\": {\"url\": img}},\n",
    "                        ],\n",
    "                    }],\n",
    "                    response_format={\"type\": \"json_object\"},\n",
    "                    temperature=self.temperature,\n",
    "                    max_tokens=self.max_tokens,\n",
    "                )\n",
    "                msg = (r.choices[0].message.content or \"{}\").strip()\n",
    "                msg = re.sub(r\"^```(?:json)?\\s*|\\s*```$\", \"\", msg)  # убираем обёртку ```json\n",
    "                data = json.loads(msg)\n",
    "                lab = normalize_label(data.get(\"label\", \"\"))\n",
    "                if not lab:\n",
    "                    raise ValueError(f\"Bad label: {data}\")\n",
    "                conf = float(data.get(\"confidence\", 0))\n",
    "                rat = str(data.get(\"rationale\", \"\"))\n",
    "                return {\"label\": lab, \"confidence\": conf, \"rationale\": rat}\n",
    "            except Exception as e:\n",
    "                last_err = e\n",
    "                if attempt < retries:\n",
    "                    time.sleep(backoff * (2 ** attempt))\n",
    "        raise RuntimeError(f\"Inference failed for {image_path.name}: {last_err}\")\n",
    "\n",
    "def evaluate(y_true: List[str], y_pred: List[str]) -> Tuple[float, float, float, float]:\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    p, r, f1, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average=\"binary\", pos_label=\"military\", zero_division=0\n",
    "    )\n",
    "    return acc, p, r, f1\n",
    "\n",
    "def plot_confusion(y_true: List[str], y_pred: List[str], title: str):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=list(LABELS))\n",
    "    fig = plt.figure()\n",
    "    ax = plt.gca()\n",
    "    im = ax.imshow(cm, interpolation=\"nearest\")\n",
    "    ax.set_xticks(range(len(LABELS))); ax.set_yticks(range(len(LABELS)))\n",
    "    ax.set_xticklabels(LABELS); ax.set_yticklabels(LABELS)\n",
    "    ax.set_xlabel(\"Predicted\"); ax.set_ylabel(\"True\"); ax.set_title(title)\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, str(cm[i, j]), ha=\"center\", va=\"center\")\n",
    "    fig.colorbar(im)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def run_eval_for_model(cfg: VLMConfig, gt: Dict[Path, str], token: str, limit: Optional[int] = None, seed: int = 42):\n",
    "    # Подготовка данных\n",
    "    items = list(gt.items())\n",
    "    if limit and len(items) > limit:\n",
    "        random.seed(seed)\n",
    "        items = random.sample(items, k=limit)\n",
    "\n",
    "    clf = HfVlmClassifier(token, cfg)\n",
    "    y_true, y_pred = [], []\n",
    "    rows = []  # накопитель для отображения\n",
    "\n",
    "    print(f\"\\n=== Model: {cfg.name}{' : ' + cfg.provider if cfg.provider else ''} ===\")\n",
    "    for idx, (path, true_lab) in enumerate(tqdm(items, desc=\"classify\", unit=\"img\"), start=1):\n",
    "        pred = clf.classify(path)\n",
    "        y_true.append(true_lab)\n",
    "        y_pred.append(pred.get(\"label\", \"\"))\n",
    "\n",
    "        rows.append({\n",
    "            \"#\": idx,\n",
    "            \"filename\": path.name,\n",
    "            \"true\": true_lab,\n",
    "            \"pred\": pred.get(\"label\", \"\"),\n",
    "            \"confidence\": float(pred.get(\"confidence\", 0)),\n",
    "        })\n",
    "\n",
    "        # Онлайн-метрики и таблица (обновляем вывод)\n",
    "        acc, p, r, f1 = evaluate(y_true, y_pred)\n",
    "        clear_output(wait=True)\n",
    "        print(f\"=== Model: {cfg.name}{' : ' + cfg.provider if cfg.provider else ''} ===\")\n",
    "        print(f\"Processed: {idx}/{len(items)}\")\n",
    "        print(f\"Accuracy: {acc:.3f}  |  Precision: {p:.3f}  Recall: {r:.3f}  F1: {f1:.3f}\")\n",
    "        df = pd.DataFrame(rows)\n",
    "        display(df.tail(min(10, len(df))))  # последние 10 строк, чтобы вывод не разрастался\n",
    "\n",
    "    # Финальные метрики + матрица ошибок\n",
    "    print(\"\\nFinal metrics:\")\n",
    "    acc, p, r, f1 = evaluate(y_true, y_pred)\n",
    "    print(f\"Accuracy: {acc:.4f}\\nPrecision: {p:.4f}\\nRecall: {r:.4f}\\nF1: {f1:.4f}\")\n",
    "    plot_confusion(y_true, y_pred, title=cfg.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfd778f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded images with labels: 30\n",
      "Labels distribution:\n",
      "military    16\n",
      "civilian    14\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# === Параметры окружения и данных ===\n",
    "load_dotenv()\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
    "if not HF_TOKEN:\n",
    "    raise RuntimeError(\"Переменная окружения HF_TOKEN не найдена. Установите токен (например, через .env).\")\n",
    "\n",
    "# Укажите директорию с изображениями и (опционально) CSV с колонками: filename,label\n",
    "DATA_DIR = Path(\"./planes\")  # TODO: замените на вашу папку с картинками\n",
    "LABELS_CSV = Path(\"./planes/labels.csv\")  # Например: Path(\"/mnt/data/planes_dataset/labels.csv\")\n",
    "\n",
    "gt = load_ground_truth(DATA_DIR, LABELS_CSV)\n",
    "print(f\"Loaded images with labels: {len(gt)}\")\n",
    "print(\"Labels distribution:\")\n",
    "print(pd.Series(list(gt.values())).value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8924db41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Модели для прогона ===\n",
    "# Убедитесь, что выбранные модели доступны через ваш HF Router аккаунт.\n",
    "MODELS = [\n",
    "    VLMConfig(name=\"Qwen/Qwen2.5-VL-7B-Instruct\"),\n",
    "    VLMConfig(name=\"llava-hf/llava-v1.6-mistral-7b-hf\", provider=\"replicate\")\n",
    "]\n",
    "LIMIT = None  # можно уменьшить для быстрого прогрева, None — без лимита\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a8d69f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Model: Qwen/Qwen2.5-VL-7B-Instruct ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "classify:   0%|          | 0/30 [00:04<?, ?img/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAPIStatusError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 93\u001b[39m, in \u001b[36mHfVlmClassifier.classify\u001b[39m\u001b[34m(self, image_path, retries, backoff)\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m     r = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[43m                \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtype\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[43m                \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtype\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mimage_url\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mimage_url\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43murl\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m}\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[43m            \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtype\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mjson_object\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    106\u001b[39m     msg = (r.choices[\u001b[32m0\u001b[39m].message.content \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m).strip()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Georgiy/Институт/МАГА/ИСИТ/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py:286\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Georgiy/Институт/МАГА/ИСИТ/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py:1156\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1155\u001b[39m validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m1156\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1157\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1158\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1159\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m   1160\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1161\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1162\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1163\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1164\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1165\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1166\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1167\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1168\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1169\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1170\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1171\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1172\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1173\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1174\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1175\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1176\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1177\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1178\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1179\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1180\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1181\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1184\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1185\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1186\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1187\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1188\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1189\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1190\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1191\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1192\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mverbosity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1194\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1195\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m   1196\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m   1197\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1198\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1199\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1200\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m   1201\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1202\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1203\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1204\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1205\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Georgiy/Институт/МАГА/ИСИТ/.venv/lib/python3.12/site-packages/openai/_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1256\u001b[39m opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m     method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Georgiy/Институт/МАГА/ИСИТ/.venv/lib/python3.12/site-packages/openai/_base_client.py:1047\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1046\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1047\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1049\u001b[39m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[31mAPIStatusError\u001b[39m: Error code: 402 - {'error': 'You have exceeded your monthly included credits for Inference Providers. Subscribe to PRO to get 20x more monthly included credits.'}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m cfg \u001b[38;5;129;01min\u001b[39;00m MODELS:\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[43mrun_eval_for_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mHF_TOKEN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mLIMIT\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 156\u001b[39m, in \u001b[36mrun_eval_for_model\u001b[39m\u001b[34m(cfg, gt, token, limit, seed)\u001b[39m\n\u001b[32m    154\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== Model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcfg.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m : \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39mcfg.provider\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39mcfg.provider\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx, (path, true_lab) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(items, desc=\u001b[33m\"\u001b[39m\u001b[33mclassify\u001b[39m\u001b[33m\"\u001b[39m, unit=\u001b[33m\"\u001b[39m\u001b[33mimg\u001b[39m\u001b[33m\"\u001b[39m), start=\u001b[32m1\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     pred = \u001b[43mclf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclassify\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    157\u001b[39m     y_true.append(true_lab)\n\u001b[32m    158\u001b[39m     y_pred.append(pred.get(\u001b[33m\"\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 118\u001b[39m, in \u001b[36mHfVlmClassifier.classify\u001b[39m\u001b[34m(self, image_path, retries, backoff)\u001b[39m\n\u001b[32m    116\u001b[39m         last_err = e\n\u001b[32m    117\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m attempt < retries:\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m             \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackoff\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mattempt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInference failed for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_path.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlast_err\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for cfg in MODELS:\n",
    "    run_eval_for_model(cfg, gt, token=HF_TOKEN, limit=LIMIT)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
